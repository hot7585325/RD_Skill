<!DOCTYPE html>
<html lang="zh-Hant">

<head>
  <meta charset="UTF-8">
  <title>PG_RD</title>
  <link rel="stylesheet" href="css\style.css">
</head>

<body>
  <div class="container">

    <!-- #region 左側欄位 -->
    <div class="sidebar">

      <div class="project" data-title="Azure AI Assistant">
        <div class="big-btn">Azure AI Assistant</div>
        <div class="mid-btns">

          <div class="mid-btn">專案理解</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-a1">概述</div>
          </div>

          <div class="mid-btn">Azure問題</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-a3">Azure的計費機制</div>
            <div class="small-btn" data-target="content-a4">LLM回答內容</div>
            <div class="small-btn" data-target="content-a5">語系強制定義</div>
            <div class="small-btn" data-target="content-a6">自訂語音</div>
            <div class="small-btn" data-target="content-a7">Viseme 嘴型 </div>
          </div>

          <div class="mid-btn">RAG實作</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-rag-1">簡介</div>
            <div class="small-btn" data-target="content-rag-2">角色分派</div>
          </div>

        </div>
      </div>

      <div class="project" data-title="WebAR">
        <div class="big-btn">WebAR</div>
        <div class="mid-btns">
          <div class="mid-btn">專案理解</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-b1">概述</div>
            <div class="small-btn" data-target="content-b2">限制</div>
          </div>

          <div class="mid-btn">相關技術</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-b3">圖片偵測</div>
            <div class="small-btn" data-target="content-b4">平面偵測</div>
            <div class="small-btn" data-target="content-b5">相關工具</div>
          </div>
        </div>
      </div>

      <div class="project" data-title="新技術分享">
        <div class="big-btn">技術分享</div>
        <div class="mid-btns">
          <div class="mid-btn">3D</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-c1">混元世界模型开源</div>
          </div>
        </div>
      </div>
    </div>
    <!-- #endregion  -->

    <!-- #region 右側內容區 -->
    <div class="content">
      <div class="title">
        <h1 id="content-title">請選擇專案</h1>
      </div>
      <div class="content-body">
        <div class="time" id="time">請選擇技術</div>
        <div id="content-text">
          <p>這裡會顯示技術內容...</p>
        </div>
      </div>
    </div>
    <!-- #endregion  -->
  </div>


  <!-- 主要內容區 -->
  <div id="hidden-contents" style="display:none;">

    <!-- #region Azure專案概述 -->
    <div id="content-a1" data-time="2025-10-27">
      <h3 class="subtitle">概述</h3>
      <p class="middletitle">Azure創建的資源</p>
      <p>Azure 裡面有很多功能服務都很相近，這邊以Service將功能區分</p>

      <p class="littletitle">Azure Speech Service</p>
      <ul>
        <li>Speech to Text (STT) – 語音轉文字</li>
        <li> Text to Speech (TTS) – 文字轉語音</li>
        <li>Viseme 嘴型事件 – 提供嘴型同步資訊</li>
        <li>Custom Neural Voice – 聲音克隆（需申請核准）</li>
      </ul>
      <p class="littletitle">Azure OpenAI Service</p>
      <ul>
        <li>GPT‑4o / GPT‑4 Turbo / GPT‑4o-mini – 大型語言模型 (LLM)</li>
        <li>DALL·E – 文字轉圖片 (Image Generation)</li>
        <li> Embeddings – 向量化，用於搜尋 / RAG</li>
      </ul>

      <p class="littletitle">Azure AI Search</p>
      <ul>
        <li>文件索引與檢索</li>
        <li>向量搜尋 (Vector Search)</li>
        <li>storage account</li>
      </ul>

      <p class="littletitle">Azure Custom Vision</p>
      <ul>
        <li>影像分類 (Classification)</li>
        <li>物件偵測 (Object Detection)</li>
        <li>訓練 (Training) – 依小時計費</li>
        <li>推論 (Prediction) – 依圖片數計費</li>
      </ul>

      <p class="littletitle">Azure AI Foundry</p>
      <ul>
        <li>模型目錄 (Model Catalog) – 整合 OpenAI、Hugging Face、Meta 等模型</li>
        <li>Responses API – 支援文字 + JSON + 工具調用</li>
        <li>Agentic Platform – 建立 AI Agent，可呼叫工具 / API</li>
        <li>Observability & Governance – 監控、治理、合規</li>
        <li>Generative Search (RAG) – 低程式碼化的 RAG 工作流程</li>
        <li>Sora (影片生成, Preview) – 文字轉影片</li>
      </ul>

    </div>
    <!-- #endregion  -->

    <!-- #region Azure的計費機制 -->
    <div id="content-a3" data-time="2025-10-17">
      <h3 class="subtitle">Azure的計費機制</h3>

      <p>在 Azure OpenAI Service 中，token 是依照輸入與輸出的文字量計算，不同模型與媒體類型（文字、圖片、語音）計費方式不一：</p>
      <p class="middletitle">文字模型</p><br>
      <ul>
        <li>Token 計算：Azure OpenAI 模型會將文本分解為 token 進行處理。每個 token 大約相當於四個字符。計費是基於每 1,000 個 token 的使用量。</li>
        <li>輸入和輸出 Token：您需要為發送的輸入 token 和接收到的輸出 token 支付費用。例如，如果您發送 1,000 個 token 的請求並接收到 1,000 個 token 的回應，則總共計費 2,000
          個 token。</li>
        <li>不同模型的費率：不同的模型和部署類型會有不同的費率。具體的費率可以在 Azure OpenAI 定價頁面 上找到。</li>
      </ul>

      <p class="middletitle">圖片生成（DALL·E）</p><br>
      <P>Azure OpenAI 的影像處理功能，結合 GPT-4o、GPT-4o-mini 和 GPT-4 Turbo with Vision
        模型，使用影像標記化來確定影像輸入所消耗的標記總數。消耗的標記數量是基於兩個主要因素計算：影像細節等級（低或高）和影像尺寸。標記成本的計算方法如下：</P>
      <ul>
        <li>圖像 token：圖像處理會將圖像分解為 token 進行計費。這些 token 的數量取決於圖像的細節和尺寸。</li>
        <li>額外功能：例如，光學字符識別（OCR）和物體定位等增強功能會產生額外的費用。</li>
      </ul>


      <p class="middletitle">語音 / 語音轉文字（Speech to Text / TTS）</p>
      <p>Azure 現支援兩類主要語音型態：語音轉文字（Speech-to-Text, STT）及文字轉語音（Text-to-Speech, TTS）。主要依音訊長度（秒/小時）或每百萬字元計價。</p>
      <p class="littletitle">語音轉文字（STT）</p>
      <ul>
        <li>標準即時轉錄：$1.00/小時（即時）；$0.369/小時（快速）；$0.181/小時（批次）</li>
        <li>自訂模型：$1.20/小時（即時）；$0.225/小時（批次</li>
      </ul>
      <p class="littletitle">文字轉語音（TTS）</p>
      <ul>
        <li>神經語音合成（Neural TTS）：$15/百萬字元（標準）；$30/百萬字元（HD）；自訂語音 $24/百萬字元</li>
        <li>- 語音服務即時模式按秒數/小時計費，支援多語、多發音人。最新 GPT 4o（即時語音對話）模型的價格以「音訊 Token」核算，最新型態亦支持按用量計費。</li>
      </ul>


      <p class="middletitle">RAG(AI Serach)</p><br>
      <p>RAG 只要一啟用免費層以外的定價層，就會<a
          href="https://learn.microsoft.com/en-us/azure/search/search-sku-manage-costs#understand-the-billing-model">固定收費</a>
      </p>
      <img src="src\ai serach 每月固定收費.png" class="rd-image">


      <h3 class="subtitle">實際計費</h3>
      <P> 目前在此專案中，有使用Azure Open AI、Speech To Text、Text To Speech、Custom Vision等資源</P>
      <p>目前使用語言模型為GPT-4-Turbo，參照地點後的表格</p>

      <p class="middletitle">驗證計費公式</p>
      <ul>
        <li> 找到 Billable 數字（實際計費單位數量）。</li>
        <li> 對照 Rate（官方定價，依 1K tokens、每分鐘、每字元或每張圖片）。</li>
        <li> 相乘後應該等於 Value（實際帳單金額）。</li>
      </ul>



      <p class="middletitle">2025/9月帳單</p>
      <img src="src\bill.png" class="rd-image">

      <h3 class="sorucelink">相關連結</h3>
      <ul>

        <li> <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/overview#tokens">Tokens 代幣</a>
        </li>
        <li> <a href=" https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/">Azure
            OpenAI 定價</a>
        </li>
        <li> <a href="https://azure.microsoft.com/zh-tw/pricing/details/cognitive-services/speech-services/">Azure
            AI語音定價</a>
        </li>
        <li> <a href="https://azure.microsoft.com/zh-tw/pricing/details/search/">Azure AI 搜尋定價(RAG)</a>
        </li>




      </ul>
    </div>
    <!-- #endregion  -->

    <!-- #region 回答時除文字外，是否可以呈現圖片或影片等其他內容 -->
    <div id="content-a4" data-time="2025-10-17">
      <h3 class="subtitle">回答時除文字外，是否可以呈現圖片或影片等其他內容</h3>
      <ul>
        <li>圖片 → 用 LLM 產生 prompt，再丟給 DALL·E。</li>
        <li>影片 → 用 LLM 產生 prompt，再丟給 Sora（Azure AI Foundry 提供，Preview）。</li>
        <li>整合方式 → 建議讓 LLM 回覆 JSON，您的程式解析後決定要呼叫哪個生成 API。</li>
      </ul>

      <a class="middletitle"
        href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/how-to/dall-e?tabs=gpt-image-1">圖片生成-DALL·E</a>
      <a class="middletitle"
        href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/concepts/video-generation?tabs=python-entra">影片生成-Sora</a>
      <a class="middletitle"
        href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/dall-e?tabs=gpt-image-1">如何使用 Azure
        OpenAI 影像生成模型</a>

    </div>
    <!-- #endregion  -->

    <!--  #region 強制指定語言以避免混用-->
    <div id="content-a5" data-time="2025-10-17">
      <h3 class="subtitle">強制指定語言以避免混用</h3>

      <p class="littletitle">方式一：Prompt 直接明確指定</p>
      <p>「請全程以繁體中文回答，請勿出現任何簡體字。」或指定 #zh-tw</p>
      <p class="littletitle">方式二：API 參數語言標籤</p>

      <ul>
        <li>- Azure TTS/ASR、翻譯 API：locale（如 zh-TW、zh-CN）</li>
        <li>- Azure Speech Service：在 session 設定強制指定 locale: zh-TW</li>
        <li>- Azure Translator：REST API 輸出時設 to=zh-Hant（繁體中文），或語言自設定</li>
      </ul>


      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li> <a href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/how-to/quota?tabs=rest">opan ai 模型</a>
        </li>
        <li> <a href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/how-to/quota?tabs=rest">opan ai 模型</a>
        </li>
      </ul>


    </div>
    <!-- #endregion  -->

    <!-- #region 語音克隆基本技術 -->
    <div id="content-a6" data-time="2025-10-17">
      <h3 class="subtitle">Azure 語音克隆基本技術</h3>
      <p>Azure Cognitive Services 的 Custom Neural Voice（自訂神經語音）即提供高階語音克隆能力，允許根據多個語音樣本訓練個人化 TTS
        音色，適用於客服、遊戲角色、數位分身等用途，但需特殊審批與嚴格資料審查。</p>

      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li>
          <a href="https://learn.microsoft.com/zh-tw/azure/ai-services/speech-service/custom-neural-voice">什麼是自定義語音？</a>
        </li>
        <li> <a href="https://speech.microsoft.com/portal/515313ba48984236874c5bdd25f58bcf/customvoice/overview">嘗試在
            Azure AI Foundry中自訂語音</a>
        </li>
      </ul>



      <br>

    </div>
    <!-- #endregion  -->

    <!-- #region viseme -->
    <div id="content-a7" data-time="2025-10-17">
      <h3 class="subtitle">Viseme嘴型</h3>
      <p class="littletitle">角色的自然嘴型</p>
      <p>Azure Speech 與 OpenAI GPT-4o 以上多模模型，皆支援在 TTS 合成語音時回傳對應嘴型動作資訊（viseme 或 blendshape），助力 3D 虛擬角色、AI
        虛擬人或遊戲角色在唇動動畫和語音完全同步。</p>
      <p class="littletitle">Unity 嘴型同步流程</p>
      <ol>
        <li>使用speech.speechSynthesizer獲取viseme</li>
        <li>在3D軟體設定好blendShape</li>
        <li>透過viseme.id與Unity Mesh.SetBlendShapeWeight設定變形權重</li>
      </ol>

      <p class="littletitle">Viseme資訊</p>
      <p>viseme.id=傳回嘴型編號</p>
      <p>viseme.AudioOffset=該嘴型對應的時間</p>
      <p>viseme.Animation=回傳55個基本blendshape表情</p>

      <p class="littletitle">參考圖</p>
      <P> 目前使用對應名稱▼</P>
      <img src="src\VisemeBS.png" class="rd-image">
      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li>
          <a
            href="https://learn.microsoft.com/zh-tw/azure/ai-services/speech-service/how-to-speech-synthesis-viseme?tabs=visemeid&pivots=programming-language-csharp#map-phonemes-to-visemes">使用
            viseme 嘴型制作參考</a>
        </li>
      </ul>
      <br>
    </div>
    <!-- #endregion  -->

    <!--#region  RAG -->
    <div id="content-rag-1" data-time="2025-10-29">
      <h3 class="subtitle">實作 RAG</h3>

      <p class="middletitle">RAG實作方法</p>
      <p>目前Azure現有的方法，目前採用第一種方式</p>

      <ol>
        <li>
          <p>直接透過Azure AI Foundry的<a
              href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/use-your-data-quickstart?tabs=keyless%2Ctypescript-keyless%2Cpython-new&pivots=ai-foundry-portal#add-your-data-using-azure-ai-foundry-portal">playGround
              /Add your data</a>去製作(不能使用免費層的AI Search Service)</p>
        </li>
        <li> <P><a
            href="https://learn.microsoft.com/zh-tw/azure/search/tutorial-rag-build-solution?context=%2Fazure%2Fai-foundry%2Fcontext%2Fcontext">自己將資料作拆分索引</a>(較繁瑣複雜)</P>
        </li>
      </ol>


eca6a7ef-182f-4e97-af82-cf6c79a09df9


      <p class="middletitle">RAG製作的基本條件</p>
      <ol>
        <li>創建storage account 帳號</li>
        <li>於storage account 建立儲存體資源(圖片1)</li>
        <li>創建Ai Search Service 資源</li>
        <li>Azure Ai Search Service 中 金鑰 > API 存取控制選擇兩者</li>
        <li>建立角色指派</li>
      </ol>

      <p>圖片1▼</p>
      <img src="src\bolb_source.png" class="rd-image">

      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li><a href="https://solwen.ai/posts/what-is-rag">什麼是 RAG？初學者也看得懂的檢索增強生成（RAG）基礎指南</a></li>
        <li> <a href="https://www.youtube.com/watch?v=WWdlme1EAGI&t=524s">RAG工作原理</a></li>
        <li> <a href="https://mapify.so/share-link/qHBmbvzIhF">RAG心智圖</a></li>
        <li><a href="https://learn.microsoft.com/zh-tw/azure/search/">Azure AI 搜尋服務文件</a></li>
        <li><a href="https://github.com/msftsean/azure-ai-foundry-demo/blob/main/docs/rag-guide.md">Azure AI Foundry RAG
            實作指南</a></li>
        <li><a
            href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/concepts/use-your-data?tabs=file-upload%2Ccopilot#streaming-data">串流資料</a>
        </li>



        <li> <a
            href="https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-4.0.0">什麼是
            Azure AI 文件智能？</a></li>

        <li> <a href="https://learn.microsoft.com/zh-tw/azure/ai-services/content-understanding/overview">什麼是 Azure AI
            內容瞭解?</a></li>
      </ul>
      <br>
    </div>

    <div id="content-rag-2" data-time="2025-10-29">
      <h3 class="subtitle">角色分派</h3>
      <p>在AI Foundry的playGround 使用Add your Data (RAG)，會有資源的權限問題，資源與資源間需要給定相應權限，詳細設定可以參考<a
          href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/on-your-data-configuration#role-assignments">Role
          assignments</a></p>
      <P>懶人包：賦予"A資源"一個你指定的角色，並把該角色的存取權限指定給"B使用者/資源"</P>
      <p>下圖是沒有分配角色時，會出現的錯誤</p>
      <img src="src\無身份錯誤.png" class="rd-image">
      <p>第一點：賦予AI Serach Resource，2個角色(Serach Service Contributor、Searce Index Data Reader)，並把該角色的存取權限都指定給Azure OpenAI
        Resource</p>
      <img src="src\無身份錯誤2.png" class="rd-image">

      <p class="middletitle">實際操作</p>
      <P>在首頁點選資源後，可以在左側欄位看到存取控制(IAM)的選項▼</P>
      <img src="src\IAM.png" class="rd-image">
      <P>在上方選項， +新增 > 新增角色指派，會移動到下方頁面，操作上直接點選該欄位，即表示使用該角色</P>
      <P>每個資源，在新增角色分派時，會顯示全部內建的角色，因為Azure目前不會依照你選擇的資源，去篩選角色，所以雖然介面有很多角色，但實際上只有一部分「對該資源有意義」</P>
      <img src="src\新增角色分派.png" class="rd-image">
      <P>而這個角色，可以給誰使用，如果以RAG為例 ，需要選擇受控識別(資源)</P>
      <img src="src\新增角色分派2.png" class="rd-image">
      <P>依照錯誤log所示，還會需要開啟 AI Search的受控識別，可以在AI Foundry > "搭配使用"中找到該資源，並點選"識別"，如下圖所示▼</P>
      <img src="src\開啟serach受控識別.png" class="rd-image">

      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li><a href="https://www.youtube.com/watch?v=4v7ffXxOnwU">Azure 基於角色的存取控制</a></li>
        <li> <a
            href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/on-your-data-configuration#role-assignments">Role
            assignments</a>
        </li>
      </ul>
      <br>
    </div>
    <!-- #endregion  -->

    <!--#region webAr -->
    <div id="content-b1" data-time="2025-10-17">
      <h3 class="subtitle">概述</h3>
      <p class="littletitle">功能簡介</p>
      <ol>
        <li>辨識圖片後生成模型</li>
        <li>可點擊按鈕播放動畫</li>
        <li>可標示重點，點擊後開啟滿版的詳細說明頁</li>
        <li>可透過手勢拖曳控制模型縮放與旋轉</li>
      </ol>

      <p class="littletitle">圖片偵測</p>
      <p>目前透過MindAR 與 A-Frame</p>
      <p>MindAR 因不使用 WebXR API，因此可在 iOS / Android 皆支援</p>

      <p class="littletitle">平面偵測</p>
      <p>Android 支援 WebXR，目前使用 three.js 的 hit-test 範例修改實作平面偵測與互動</p>
      <p>iOS Safari 因為不完全支援 WebXR</p>

    </div>
    <!-- #endregion  -->

    <!-- #region 技術分享 -->
    <div id="content-c1" data-time="2025-10-23">
      <h3 class="subtitle">混元世界模型开源</h3>
      <p class="littletitle">功能簡介</p>
      <p>一個統一的前饋式 3D 重建模型，支援多模態先驗輸入，實現點雲、深度、相機位姿、表面法線和新視角合成等多任務 3D 幾何預測</p>


      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li>
          <a href="https://3d-models.hunyuan.tencent.com/world/">混元世界模型開源</a>
        </li>
      </ul>
    </div>
    <!-- #endregion  -->



  </div>

  <script src="js\main.js"></script>
</body>

</html>