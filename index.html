<!DOCTYPE html>
<html lang="zh-Hant">

<head>
  <meta charset="UTF-8">
  <title>PG_RD</title>
  <link rel="stylesheet" href="css\style.css">
</head>

<body>
  <div class="container">

    <!-- #region 左側欄位 -->
    <div class="sidebar">

      <div class="project" data-title="Azure AI Assistant">
        <div class="big-btn">Azure AI Assistant</div>
        <div class="mid-btns">

          <div class="mid-btn">專案理解</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-a1">概述</div>
          </div>

          <div class="mid-btn">Azure問題</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-a3">Azure的計費機制</div>
            <div class="small-btn" data-target="content-a4">多模態內容回應</div>
            <div class="small-btn" data-target="content-a5">語系強制定義</div>
            <div class="small-btn" data-target="content-a6">自訂語音</div>
            <div class="small-btn" data-target="content-a7">Viseme 嘴型 </div>
          </div>

          <div class="mid-btn">RAG實作</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-rag-1">簡介</div>
            <div class="small-btn" data-target="content-rag-2">角色分派</div>
            <div class="small-btn" data-target="content-rag-3">PlayGround-RAG</div>
            <div class="small-btn" data-target="content-rag-4">多模態資料</div>
          </div>

        </div>
      </div>

      <!-- <div class="project" data-title="WebAR">
        <div class="big-btn">WebAR</div>
        <div class="mid-btns">
          <div class="mid-btn">專案理解</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-b1">概述</div>
            <div class="small-btn" data-target="content-b2">限制</div>
          </div>

          <div class="mid-btn">相關技術</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-b3">圖片偵測</div>
            <div class="small-btn" data-target="content-b4">平面偵測</div>
            <div class="small-btn" data-target="content-b5">相關工具</div>
          </div>
        </div>
      </div> -->

      <!-- <div class="project" data-title="新技術分享">
        <div class="big-btn">技術分享</div>
        <div class="mid-btns">
          <div class="mid-btn">3D</div>
          <div class="small-btns">
            <div class="small-btn" data-target="content-c1">混元世界模型开源</div>
          </div>
        </div>
      </div> -->
    </div>
    <!-- #endregion  -->

    <!-- #region 右側內容區 -->
    <div class="content">
      <div class="title">
        <h1 id="content-title">請選擇專案</h1>
      </div>
      <div class="content-body">
        <div class="time" id="time">請選擇技術</div>
        <div id="content-text">
          <p>這裡會顯示技術內容...</p>
        </div>
      </div>
    </div>
    <!-- #endregion  -->
  </div>


  <!-- 主要內容區 -->
  <div id="hidden-contents" style="display:none;">

    <!-- #region Azure專案概述 -->
    <div id="content-a1" data-time="2025-10-27">
      <h3 class="subtitle">概述</h3>

      <p class="middletitle">期望運作方式</p>
      <ol>
        <li>透過點擊上傳檔案按鈕</li>
        <li>呼叫產生SAS</li>
        <li>轉成Byte</li>
        <li>儲存Blob storage</li>
        <li>啟用Content Understanding</li>
      </ol>
      </P>
      <a
        href="https://learn.microsoft.com/zh-tw/azure/storage/common/storage-sas-overview#how-a-shared-access-signature-works"></a>



      <p class="middletitle">Azure創建的資源</p>
      <p>Azure 裡面有很多功能服務都很相近，這邊以Service將功能區分</p>

      <p class="littletitle">Azure Speech Service</p>
      <ul>
        <li>Speech to Text (STT) – 語音轉文字</li>
        <li> Text to Speech (TTS) – 文字轉語音</li>
        <li>Viseme 嘴型事件 – 提供嘴型同步資訊</li>
        <li>Custom Neural Voice – 聲音克隆（需申請核准）</li>
      </ul>
      <p class="littletitle">Azure OpenAI Service</p>
      <ul>
        <li>GPT‑4o / GPT‑4 Turbo / GPT‑4o-mini – 大型語言模型 (LLM)</li>
        <li>DALL·E – 文字轉圖片 (Image Generation)</li>
        <li> Embeddings – 向量化，用於搜尋 / RAG</li>
      </ul>

      <p class="littletitle">Azure AI Search</p>
      <ul>
        <li>文件索引與檢索</li>
        <li>向量搜尋 (Vector Search)</li>
        <li>storage account</li>
      </ul>

      <p class="littletitle">Azure Custom Vision</p>
      <ul>
        <li>影像分類 (Classification)</li>
        <li>物件偵測 (Object Detection)</li>
        <li>訓練 (Training) – 依小時計費</li>
        <li>推論 (Prediction) – 依圖片數計費</li>
      </ul>

      <p class="littletitle">Azure AI Foundry</p>
      <ul>
        <li>模型目錄 (Model Catalog) – 整合 OpenAI、Hugging Face、Meta 等模型</li>
        <li>Responses API – 支援文字 + JSON + 工具調用</li>
        <li>Agentic Platform – 建立 AI Agent，可呼叫工具 / API</li>
        <li>Observability & Governance – 監控、治理、合規</li>
        <li>Generative Search (RAG) – 低程式碼化的 RAG 工作流程</li>
        <li>Sora (影片生成, Preview) – 文字轉影片</li>
      </ul>

    </div>
    <!-- #endregion  -->

    <!-- #region Azure的計費機制 -->
    <div id="content-a3" data-time="2025-10-17">
      <h3 class="subtitle">計費方式概述</h3>

      <p>Azure OpenAI 提供兩種主要計費選項：標準隨用隨付 (Standard On-Demand) 按實際使用的輸入和輸出 token 數計費，以及預配吞吐量單位 (Provisioned Throughput
        Units, PTUs) 以固定成本提供可預測的定價，適合高容量應用。</p>
      <p class="middletitle">文字 Token 計費</p><br>
      <p>文字內容根據模型而異。對於 GPT-4o，輸入 token 成本為每百萬 token $2.50，輸出 token 為每百萬 token $10.00。 成本根據所使用的具體模型而異，例如 GPT-3.5-Turbo
        的成本更低，而 o1 推理模型的成本更高。</p>

      <p class="middletitle">圖片 Token 計費</p><br>
      <P>A圖片的 token 計費涉及複雜的計算過程。低解析度模式將圖片編碼為 85 個 base token。 高解析度模式則需要多個步驟：</P>
      <p class="littletitle">高解析度圖片的 Token 計算步驟：</p>
      <ol class="outline">
        <li>圖片調整大小：圖片首先調整到 2048 × 2048 像素的正方形內。如果最短邊大於 768 像素，再次調整使最短邊為 768 像素。</li>
        <li>磁磚分割：調整後的圖片分割成 512 × 512 像素的磁磚，不完整的磁磚向上取整為完整磁磚。</li>
        <li>Token 計算：
          <ul>
            <li>GPT-4o 和 GPT-4 Turbo with Vision：每個 512 × 512 像素磁磚成本為 170 token，加上 85 個 base token</li>
            <li>GPT-4o mini：每個 512 × 512 像素磁磚成本為 5,667 token，加上 2,833 個 base token</li>
          </ul>
        </li>
      </ol>

      <p class="middletitle">音訊 Token 計費</p>
      <p>音訊有兩種方式，計費方式也不同</p>
      <p class="littletitle">多模態模型如 GPT-4o-Realtime 和 GPT-audio 將音訊內容轉換為 token：</p>
      <ul>
        <li>GPT-Realtime 音訊輸入：每百萬 token $32.00</li>
        <li>GPT-Realtime 音訊輸出：每百萬 token $64.00n</li>
      </ul>
      <p class="littletitle">Azure Speech Services</p>
      <ul>
        <li>Text-to-Speech (TTS) 定價：計費單位：按字元數計費（per character）<ul></ul>
        </li>
        <li>Speech-to-Text (STT) 定價：計費單位：按音訊時長計費（per hour）</li>
      </ul>

      <p class="middletitle">影像 (Sora) 計費</p>
      <p>Azure 中的 Sora 2 影像生成 採用每秒計費模式，而非 token 計費：</p>
      <ul>
        <li>Sora 2 標準版（720 × 1280 或 1280 × 720）：$0.10 美元/秒</li>
        <li>Sora 2 專業版（1024 × 1792 或 1792 × 1024）：$0.20 美元/秒</li>
      </ul>




      <p class="middletitle">RAG(AI Serach)</p><br>
      <p>RAG 只要一啟用免費層以外的定價層，就會<a
          href="https://learn.microsoft.com/en-us/azure/search/search-sku-manage-costs#understand-the-billing-model">固定收費</a>
      </p>
      <img src="src\ai serach 每月固定收費.png" class="rd-image">

      <p>目前使用基本層▼</p>
      <img src="src\aiSearch_定價層.png" class="rd-image">

      <h3 class="subtitle">實際計費</h3>
      <P>目前在此專案中，有使用Azure Open AI、Speech To Text、Text To Speech、Custom Vision等資源</P>
      <p>目前使用語言模型為GPT-4-Turbo，參照地點後的表格</p>


      <p class="middletitle">2025/9月帳單</p>
      <img src="src\bill.png" class="rd-image">

      <h3 class="sorucelink">相關連結</h3>
      <ul>

        <li> <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/overview#tokens">Tokens 代幣</a>
        </li>
        <li> <a href=" https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/">Azure
            OpenAI 定價</a>
        </li>
        <li> <a href="https://azure.microsoft.com/zh-tw/pricing/details/cognitive-services/speech-services/">Azure
            AI語音定價</a>
        </li>
        <li> <a href="https://azure.microsoft.com/zh-tw/pricing/details/search/">Azure AI 搜尋定價(RAG)</a>
        </li>




      </ul>
    </div>
    <!-- #endregion  -->

    <!-- #region 回答時除文字外，是否可以呈現圖片或影片等其他內容 -->
    <div id="content-a4" data-time="2025-10-17">
      <h3 class="subtitle">多模態內容回應</h3>
      <p class="middletitle">簡易區分，生成與檢索回復兩個方式</p><br>

      <p class="littletitle">內容生成：</p>
      <ul class="outline">
        <li>圖片 → 用 LLM 產生 prompt，再丟給 DALL·E。</li>
        <li>影片 → 用 LLM 產生 prompt，再丟給 Sora（Azure AI Foundry 提供，Preview）。</li>
        <li>整合方式 → 建議讓 LLM 回覆 JSON，您的程式解析後決定要呼叫哪個生成 API。</li>
      </ul>

      <p class="littletitle">檢索回復：</p>


      <br>

      <br>


      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li>
          <a
            href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/how-to/dall-e?tabs=gpt-image-1">圖片生成-DALL·E</a>
        </li>
        <li>
          <a
            href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/concepts/video-generation?tabs=python-entra">影片生成-Sora</a>
        </li>
        <li>
          <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/dall-e?tabs=gpt-image-1">如何使用 Azure
            OpenAI 影像生成模型</a>
        </li>
      </ul>



    </div>
    <!-- #endregion  -->

    <!--  #region 強制指定語言以避免混用-->
    <div id="content-a5" data-time="2025-10-17">
      <h3 class="subtitle">強制指定語言以避免混用</h3>

      <p class="littletitle">方式一：Prompt 直接明確指定</p>
      <p>「請全程以繁體中文回答，請勿出現任何簡體字。」或指定 #zh-tw</p>
      <p class="littletitle">方式二：API 參數語言標籤</p>

      <ul>
        <li>- Azure TTS/ASR、翻譯 API：locale（如 zh-TW、zh-CN）</li>
        <li>- Azure Speech Service：在 session 設定強制指定 locale: zh-TW</li>
        <li>- Azure Translator：REST API 輸出時設 to=zh-Hant（繁體中文），或語言自設定</li>
      </ul>
    </div>
    <!-- #endregion  -->

    <!-- #region 語音克隆基本技術 -->
    <div id="content-a6" data-time="2025-10-17">
      <h3 class="subtitle">Azure 語音克隆基本技術</h3>
      <p>Azure Cognitive Services 的 Custom Neural Voice（自訂神經語音）即提供高階語音克隆能力，允許根據多個語音樣本訓練個人化 TTS
        音色，適用於客服、遊戲角色、數位分身等用途，但需特殊審批與嚴格資料審查。</p>

      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li>
          <a href="https://learn.microsoft.com/zh-tw/azure/ai-services/speech-service/custom-neural-voice">什麼是自定義語音？</a>
        </li>
        <li> <a href="https://speech.microsoft.com/portal/515313ba48984236874c5bdd25f58bcf/customvoice/overview">嘗試在
            Azure AI Foundry中自訂語音</a>
        </li>
      </ul>



      <br>

    </div>
    <!-- #endregion  -->

    <!-- #region viseme -->
    <div id="content-a7" data-time="2025-10-17">
      <h3 class="subtitle">Viseme嘴型</h3>
      <p class="littletitle">角色的自然嘴型</p>
      <p>Azure Speech 與 OpenAI GPT-4o 以上多模模型，皆支援在 TTS 合成語音時回傳對應嘴型動作資訊（viseme 或 blendshape），助力 3D 虛擬角色、AI
        虛擬人或遊戲角色在唇動動畫和語音完全同步。</p>
      <p class="littletitle">Unity 嘴型同步流程</p>
      <ol>
        <li>使用speech.speechSynthesizer獲取viseme</li>
        <li>在3D軟體設定好blendShape</li>
        <li>透過viseme.id與Unity Mesh.SetBlendShapeWeight設定變形權重</li>
      </ol>

      <p class="littletitle">Viseme資訊</p>
      <p>viseme.id=傳回嘴型編號</p>
      <p>viseme.AudioOffset=該嘴型對應的時間</p>
      <p>viseme.Animation=回傳55個基本blendshape表情</p>

      <p class="littletitle">參考圖</p>
      <P> 目前使用對應名稱▼</P>
      <img src="src\VisemeBS.png" class="rd-image">
      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li>
          <a
            href="https://learn.microsoft.com/zh-tw/azure/ai-services/speech-service/how-to-speech-synthesis-viseme?tabs=visemeid&pivots=programming-language-csharp#map-phonemes-to-visemes">使用
            viseme 嘴型制作參考</a>
        </li>
      </ul>
      <br>
    </div>
    <!-- #endregion  -->

    <!--#region  RAG -->
    <div id="content-rag-1" data-time="2025-10-29">
      <h3 class="subtitle">實作 RAG</h3>

      <p class="middletitle">RAG實作方法</p>
      <p>目前Azure現有的方法</p>

      <ol>
        <li>
          <P><a
              href="https://learn.microsoft.com/zh-tw/azure/search/tutorial-rag-build-solution?context=%2Fazure%2Fai-foundry%2Fcontext%2Fcontext">傳統方式</a>：自行建構解析Pipline，較困難，需要自己切分與內嵌
          </P>
        </li>
        <li>
          <p>直接透過Azure AI Foundry的<a
              href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/use-your-data-quickstart?tabs=keyless%2Ctypescript-keyless%2Cpython-new&pivots=ai-foundry-portal#add-your-data-using-azure-ai-foundry-portal">playGround
              /Add your data</a>：僅限文字；不能使用免費層的AI Search Service</p>
        </li>
      </ol>
      <p class="littletitle">傳統RAG製作步驟</p>
      <ol>
        <li>切分文字（chunking） ：</li>
      </ol>


      <p class="middletitle">RAG製作的基本條件</p>
      <ol class="outline">
        <li>創建storage account 帳號</li>
        <li>於storage account 建立儲存體資源(圖片1)</li>
        <li>創建Ai Search Service 資源</li>
        <li>Azure Ai Search Service 中 金鑰 > API 存取控制選擇兩者</li>
        <li>建立角色指派</li>
      </ol>

      <p>圖片1▼</p>
      <img src="src\bolb_source.png" class="rd-image">

      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li><a href="https://solwen.ai/posts/what-is-rag">什麼是 RAG？初學者也看得懂的檢索增強生成（RAG）基礎指南</a></li>
        <li> <a href="https://www.youtube.com/watch?v=WWdlme1EAGI&t=524s">RAG工作原理</a></li>
        <li> <a href="https://mapify.so/share-link/qHBmbvzIhF">RAG心智圖</a></li>
        <li><a href="https://learn.microsoft.com/zh-tw/azure/search/">Azure AI 搜尋服務文件</a></li>
        <li><a href="https://github.com/msftsean/azure-ai-foundry-demo/blob/main/docs/rag-guide.md">Azure AI Foundry RAG
            實作指南</a></li>
        <li><a
            href="https://learn.microsoft.com/zh-tw/azure/ai-foundry/openai/concepts/use-your-data?tabs=file-upload%2Ccopilot#streaming-data">串流資料</a>
        </li>



        <li> <a
            href="https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-4.0.0">什麼是
            Azure AI 文件智能？</a></li>

        <li> <a href="https://learn.microsoft.com/zh-tw/azure/ai-services/content-understanding/overview">什麼是 Azure AI
            內容瞭解?</a></li>
      </ul>
      <br>
    </div>

    <div id="content-rag-2" data-time="2025-10-29">
      <h3 class="subtitle">角色分派</h3>
      <p>在AI Foundry的playGround 使用Add your Data (RAG)，會有資源的權限問題，資源與資源間需要給定相應權限，詳細設定可以參考<a
          href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/on-your-data-configuration#role-assignments">Role
          assignments</a></p>
      <P>懶人包：賦予"A資源"一個你指定的角色，並把該角色的存取權限指定給"B使用者/資源"</P>
      <p>下圖是沒有分配角色時，會出現的錯誤</p>
      <img src="src\無身份錯誤.png" class="rd-image">
      <p>第一點：賦予AI Serach Resource，2個角色(Serach Service Contributor、Searce Index Data Reader)，並把該角色的存取權限都指定給Azure OpenAI
        Resource</p>
      <img src="src\無身份錯誤2.png" class="rd-image">

      <p class="middletitle">實際操作</p>
      <P>在首頁點選資源後，可以在左側欄位看到存取控制(IAM)的選項▼</P>
      <img src="src\IAM.png" class="rd-image">
      <P>在上方選項， +新增 > 新增角色指派，會移動到下方頁面，操作上直接點選該欄位，即表示使用該角色</P>
      <P>每個資源，在新增角色分派時，會顯示全部內建的角色，因為Azure目前不會依照你選擇的資源，去篩選角色，所以雖然介面有很多角色，但實際上只有一部分「對該資源有意義」</P>
      <img src="src\新增角色分派.png" class="rd-image">
      <P>而這個角色，可以給誰使用，如果以RAG為例 ，需要選擇受控識別(資源)</P>
      <img src="src\新增角色分派2.png" class="rd-image">
      <P>依照錯誤log所示，還會需要開啟 AI Search的受控識別，可以在AI Foundry > "搭配使用"中找到該資源，並點選"識別"，如下圖所示▼</P>
      <img src="src\開啟serach受控識別.png" class="rd-image">

      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li><a href="https://www.youtube.com/watch?v=4v7ffXxOnwU">Azure 基於角色的存取控制</a></li>
        <li> <a
            href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/on-your-data-configuration#role-assignments">Role
            assignments</a>
        </li>
      </ul>
      <br>
    </div>

    <div id="content-rag-3" data-time="2025-11-03">
      <h3 class="subtitle">使用playGround實現RAG功能</h3>
      <ol class="outline">
        <li>在AI Foundry的playGround 使用Add your Data</li>
        <li>上傳資料後，需要設置"文件索引(index_name)"；可透過更換index_name來變更RAG的內容</li>
        <li>完成上傳後，點選檢視程式碼"，選擇json 與Azure OpenAI SDK，可以看到request的josn結構</li>
        <li>自訂結構類別，且不須更換端點</li>
        <li>確保reques的類別，有data_sources陣列，且不為空值</li>
      </ol>
      <br>
    </div>

    <div id="content-rag-4" data-time="2025-11-05">
      <h3 class="subtitle">使用Content Understanding(內容理解)實現多模態"訊息增強"功能</h3>

      <p class="littletitle">概觀</p>
      <p>透過POST(輸入FileURL) > GET(Json) > Send Message list ="訊息增強"</p>
      <p></p>

      <p class="littletitle">簡易步驟</p>
      <ol class="outline">
        <li>透過foundry 內容理解(CU)的POST API 傳入url(公開網址/blob storage url)</li>
        <li>POST後，會立即分析文字，需要一定時間，不會馬上回應，所以必須透過GET 持續請求(CU不會回傳成功通知)</li>
        <li>Unity中CU腳本提供方法，供UI按鈕更換分析器，這裡影響post請求 與get接收的類別結構(每個分析器不同，目前僅有圖片與影片)</li>
        <li>回傳後加入Message的陣列，所以本質上不能算完整的RAG</li>
        <li>如果需要RAG 需要將cu解析後的數據 存回Add your data /或用內嵌模型 製作向量資料庫</li>
      </ol>

      <a
        href="https://learn.microsoft.com/zh-tw/azure/ai-services/content-understanding/tutorial/create-custom-analyzer?tabs=video#sample-response">不同分析器，josn不同</a>


      <p class="littletitle">詳細步驟</p>
      <ol class="outline">
        <li>在AI Foundry的playGround 使用內容理解</li>
        <li>僅支援部分<a
            href="https://learn.microsoft.com/zh-tw/azure/ai-services/content-understanding/language-region-support#region-support">地區</a>
        </li>
        <li>端點不能使用Foundry專案的端點，要使用Azure AI 服務的端點(Azure AI Foundry > 概觀 > 端點和金鑰)</li>
        <li><img class="rd-image" src="src\內容理解的端點與金鑰位置.png"></li>
        <li>使用post 請求，analyzerId可以參考<a
            href="https://learn.microsoft.com/zh-tw/azure/ai-services/content-understanding/concepts/prebuilt-analyzers#prebuilt-analyzers-for-content-ingestion"></a>
        </li>
        <li></li>
        <li></li>
      </ol>
      <br>
    </div>





    <!-- #endregion  -->

    <!--#region webAr -->
    <div id="content-b1" data-time="2025-10-17">
      <h3 class="subtitle">概述</h3>
      <p class="littletitle">功能簡介</p>
      <ol>
        <li>辨識圖片後生成模型</li>
        <li>可點擊按鈕播放動畫</li>
        <li>可標示重點，點擊後開啟滿版的詳細說明頁</li>
        <li>可透過手勢拖曳控制模型縮放與旋轉</li>
      </ol>

      <p class="littletitle">圖片偵測</p>
      <p>目前透過MindAR 與 A-Frame</p>
      <p>MindAR 因不使用 WebXR API，因此可在 iOS / Android 皆支援</p>

      <p class="littletitle">平面偵測</p>
      <p>Android 支援 WebXR，目前使用 three.js 的 hit-test 範例修改實作平面偵測與互動</p>
      <p>iOS Safari 因為不完全支援 WebXR</p>

    </div>
    <!-- #endregion  -->

    <!-- #region 技術分享 -->
    <div id="content-c1" data-time="2025-10-23">
      <h3 class="subtitle">混元世界模型开源</h3>
      <p class="littletitle">功能簡介</p>
      <p>一個統一的前饋式 3D 重建模型，支援多模態先驗輸入，實現點雲、深度、相機位姿、表面法線和新視角合成等多任務 3D 幾何預測</p>


      <h3 class="sorucelink">相關連結</h3>
      <ul>
        <li>
          <a href="https://3d-models.hunyuan.tencent.com/world/">混元世界模型開源</a>
        </li>
      </ul>
    </div>
    <!-- #endregion  -->



  </div>

  <script src="js\main.js"></script>
</body>

</html>